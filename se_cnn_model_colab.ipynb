{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SE-CNN Marketing Optimization Model\n",
        "## Squeeze-and-Excitation CNN for Marketing Campaign Optimization\n",
        "\n",
        "This notebook implements a complete pipeline for marketing optimization using a SE-CNN model with:\n",
        "- Multi-task learning (Classification + Regression)\n",
        "- Squeeze-and-Excitation (SE) channel attention blocks\n",
        "- Budget optimization using linear programming\n",
        "\n",
        "**Instructions:**\n",
        "1. Upload your `Dataset.csv` file when prompted\n",
        "2. Run all cells sequentially\n",
        "3. View results in the output cells\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install Dependencies\n",
        "!pip install -q numpy>=1.26.0 pandas>=2.0.3 scikit-learn>=1.3.0 tensorflow>=2.15.0 matplotlib>=3.7.2 seaborn>=0.12.2 scipy>=1.11.1 pulp>=2.7.0 joblib>=1.3.2\n",
        "\n",
        "print(\"✓ All dependencies installed successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import Libraries\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import joblib\n",
        "from datetime import datetime\n",
        "\n",
        "# TensorFlow\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, Model\n",
        "\n",
        "# Scikit-learn\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    roc_auc_score, confusion_matrix, classification_report,\n",
        "    mean_absolute_error, mean_squared_error, r2_score, roc_curve\n",
        ")\n",
        "\n",
        "# Optimization\n",
        "import pulp\n",
        "from pulp import LpProblem, LpMaximize, LpVariable, lpSum, LpStatus\n",
        "\n",
        "print(\"✓ All libraries imported successfully!\")\n",
        "print(f\"TensorFlow version: {tf.__version__}\")\n",
        "print(f\"NumPy version: {np.__version__}\")\n",
        "print(f\"Pandas version: {pd.__version__}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration\n",
        "# ===================== PATHS =====================\n",
        "BASE_DIR = '/content'\n",
        "DATA_DIR = os.path.join(BASE_DIR, 'data')\n",
        "MODELS_DIR = os.path.join(BASE_DIR, 'models')\n",
        "RESULTS_DIR = os.path.join(BASE_DIR, 'results')\n",
        "\n",
        "# Create directories\n",
        "os.makedirs(DATA_DIR, exist_ok=True)\n",
        "os.makedirs(MODELS_DIR, exist_ok=True)\n",
        "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
        "\n",
        "# Dataset path (will be set after upload)\n",
        "DATASET_PATH = None  # Will be set after file upload\n",
        "\n",
        "# ===================== DATA PREPROCESSING =====================\n",
        "NUMERICAL_FEATURES = [\n",
        "    'CPC_USD', 'CTR', 'Conversion_Rate', 'Impressions',\n",
        "    'Clicks', 'Spend_USD', 'ROI', 'Click_Through_Lift',\n",
        "    'Cost_per_Lead', 'LTV_Proxy'\n",
        "]\n",
        "\n",
        "CATEGORICAL_FEATURES = ['Platform', 'Country', 'Campaign_ID']\n",
        "\n",
        "CLASSIFICATION_TARGET = 'High_Performing_Label'\n",
        "REGRESSION_TARGET = 'LTV_Proxy'\n",
        "\n",
        "TRAIN_RATIO = 0.70\n",
        "VAL_RATIO = 0.15\n",
        "TEST_RATIO = 0.15\n",
        "\n",
        "CTR_PERCENTILE = 75\n",
        "CPC_PERCENTILE = 25\n",
        "\n",
        "# ===================== MODEL ARCHITECTURE =====================\n",
        "CONV_FILTERS_1 = 32\n",
        "CONV_FILTERS_2 = 64\n",
        "KERNEL_SIZE = 3\n",
        "POOL_SIZE = 2\n",
        "DENSE_UNITS = 64\n",
        "DROPOUT_RATE = 0.2\n",
        "SE_REDUCTION_RATIO = 16\n",
        "EMBEDDING_DIM = 8\n",
        "\n",
        "# ===================== TRAINING PARAMETERS =====================\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 20\n",
        "LEARNING_RATE = 0.001\n",
        "EARLY_STOPPING_PATIENCE = 15\n",
        "LR_REDUCTION_PATIENCE = 10\n",
        "LR_REDUCTION_FACTOR = 0.5\n",
        "MIN_LEARNING_RATE = 1e-6\n",
        "TRAIN_VERBOSE = 1  # Show training progress\n",
        "\n",
        "CLASSIFICATION_LOSS_WEIGHT = 0.6\n",
        "REGRESSION_LOSS_WEIGHT = 0.4\n",
        "\n",
        "# ===================== OPTIMIZATION PARAMETERS =====================\n",
        "TOTAL_BUDGET = 200000\n",
        "MIN_BUDGET_PER_CAMPAIGN = 100\n",
        "MAX_BUDGET_PER_CAMPAIGN = 50000\n",
        "\n",
        "PLATFORM_BUDGET_CONSTRAINTS = {\n",
        "    'Google': (0.2, 0.6),\n",
        "    'Meta': (0.15, 0.5),\n",
        "    'Twitter': (0.1, 0.5),\n",
        "    'LinkedIn': (0.1, 0.4),\n",
        "    'TikTok': (0.1, 0.2)\n",
        "}\n",
        "\n",
        "# ===================== RANDOM SEED =====================\n",
        "RANDOM_SEED = 42\n",
        "\n",
        "# Set seeds\n",
        "np.random.seed(RANDOM_SEED)\n",
        "random.seed(RANDOM_SEED)\n",
        "tf.random.set_seed(RANDOM_SEED)\n",
        "\n",
        "print(\"✓ Configuration loaded!\")\n",
        "print(f\"Random seed: {RANDOM_SEED}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Upload Dataset\n",
        "from google.colab import files\n",
        "\n",
        "print(\"Please upload your Dataset.csv file:\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Get the uploaded file path\n",
        "for filename in uploaded.keys():\n",
        "    if filename.endswith('.csv'):\n",
        "        DATASET_PATH = os.path.join(DATA_DIR, filename)\n",
        "        # Move uploaded file to data directory\n",
        "        os.rename(filename, DATASET_PATH)\n",
        "        print(f\"✓ Dataset uploaded: {DATASET_PATH}\")\n",
        "        break\n",
        "\n",
        "if DATASET_PATH is None:\n",
        "    print(\"⚠ Warning: No CSV file found. Please upload Dataset.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Utility Functions\n",
        "def print_banner(text):\n",
        "    \"\"\"Print a formatted banner\"\"\"\n",
        "    width = 80\n",
        "    print(\"\\n\" + \"=\"*width)\n",
        "    print(text.center(width))\n",
        "    print(\"=\"*width + \"\\n\")\n",
        "\n",
        "print_banner(\"SE-CNN-BASED MARKETING OPTIMIZATION FRAMEWORK\")\n",
        "print(\"Model: Squeeze-and-Excitation CNN with Channel Attention\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data Preprocessing Class\n",
        "class DataPreprocessor:\n",
        "    def __init__(self):\n",
        "        self.scaler = StandardScaler()\n",
        "        self.label_encoders = {}\n",
        "        self.feature_dims = {}\n",
        "        \n",
        "    def load_data(self, filepath):\n",
        "        \"\"\"Load dataset from CSV\"\"\"\n",
        "        print(f\"Loading data from {filepath}...\")\n",
        "        df = pd.read_csv(filepath)\n",
        "        print(f\"Initial dataset shape: {df.shape}\")\n",
        "        return df\n",
        "    \n",
        "    def clean_data(self, df):\n",
        "        \"\"\"Clean dataset: remove nulls, duplicates, invalid entries\"\"\"\n",
        "        print(\"\\n=== Data Cleaning ===\")\n",
        "        initial_rows = len(df)\n",
        "        \n",
        "        # Remove completely empty rows\n",
        "        df = df.dropna(how='all')\n",
        "        print(f\"Removed {initial_rows - len(df)} empty rows\")\n",
        "        \n",
        "        # Remove duplicate Ad_IDs\n",
        "        initial_rows = len(df)\n",
        "        if 'Ad_ID' in df.columns:\n",
        "            df = df.drop_duplicates(subset=['Ad_ID'], keep='first')\n",
        "            print(f\"Removed {initial_rows - len(df)} duplicate Ad_IDs\")\n",
        "        \n",
        "        # Remove rows with missing critical features\n",
        "        critical_cols = ['CPC_USD', 'CTR', 'Conversion_Rate', 'Platform', 'Country']\n",
        "        critical_cols = [col for col in critical_cols if col in df.columns]\n",
        "        initial_rows = len(df)\n",
        "        df = df.dropna(subset=critical_cols)\n",
        "        print(f\"Removed {initial_rows - len(df)} rows with missing critical data\")\n",
        "        \n",
        "        # Remove outliers using IQR method\n",
        "        numerical_cols = [col for col in NUMERICAL_FEATURES if col in df.columns]\n",
        "        initial_rows = len(df)\n",
        "        \n",
        "        for col in numerical_cols:\n",
        "            Q1 = df[col].quantile(0.25)\n",
        "            Q3 = df[col].quantile(0.75)\n",
        "            IQR = Q3 - Q1\n",
        "            lower_bound = Q1 - 3 * IQR\n",
        "            upper_bound = Q3 + 3 * IQR\n",
        "            df = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]\n",
        "        \n",
        "        print(f\"Removed {initial_rows - len(df)} outlier rows\")\n",
        "        print(f\"Final cleaned dataset shape: {df.shape}\\n\")\n",
        "        \n",
        "        return df.reset_index(drop=True)\n",
        "    \n",
        "    def engineer_features(self, df):\n",
        "        \"\"\"Feature engineering: calculate derived features\"\"\"\n",
        "        print(\"=== Feature Engineering ===\")\n",
        "        \n",
        "        # Recalculate High_Performing_Label\n",
        "        ctr_threshold = df['CTR'].quantile(CTR_PERCENTILE / 100)\n",
        "        cpc_threshold = df['CPC_USD'].quantile(CPC_PERCENTILE / 100)\n",
        "        \n",
        "        df[CLASSIFICATION_TARGET] = (\n",
        "            (df['CTR'] >= ctr_threshold) & \n",
        "            (df['CPC_USD'] <= cpc_threshold)\n",
        "        ).astype(int)\n",
        "        \n",
        "        print(f\"High-performing threshold: CTR >= {ctr_threshold:.4f}, CPC <= {cpc_threshold:.4f}\")\n",
        "        print(f\"High-performing campaigns: {df[CLASSIFICATION_TARGET].sum()} / {len(df)}\")\n",
        "        print(f\"Class distribution: {df[CLASSIFICATION_TARGET].value_counts().to_dict()}\")\n",
        "        \n",
        "        # Ensure LTV_Proxy exists\n",
        "        if REGRESSION_TARGET not in df.columns or df[REGRESSION_TARGET].isna().any():\n",
        "            df[REGRESSION_TARGET] = df['CTR'] * df['CPC_USD'] * df['Conversion_Rate']\n",
        "            print(\"Recalculated LTV_Proxy\")\n",
        "        \n",
        "        # Additional derived features\n",
        "        if 'ROI' not in df.columns or df['ROI'].isna().any():\n",
        "            df['ROI'] = (df['Conversion_Rate'] * 100) / (df['CPC_USD'] + 1e-6)\n",
        "        \n",
        "        if 'Cost_per_Lead' not in df.columns or df['Cost_per_Lead'].isna().any():\n",
        "            conversions = df['Clicks'] * df['Conversion_Rate']\n",
        "            df['Cost_per_Lead'] = df['Spend_USD'] / (conversions + 1e-6)\n",
        "        \n",
        "        print(f\"Features engineered successfully\\n\")\n",
        "        return df\n",
        "    \n",
        "    def encode_categorical(self, df, fit=True):\n",
        "        \"\"\"Encode categorical features\"\"\"\n",
        "        print(\"=== Encoding Categorical Features ===\")\n",
        "        \n",
        "        for col in CATEGORICAL_FEATURES:\n",
        "            if col in df.columns:\n",
        "                if fit:\n",
        "                    self.label_encoders[col] = LabelEncoder()\n",
        "                    df[col] = self.label_encoders[col].fit_transform(df[col].astype(str))\n",
        "                    self.feature_dims[col] = len(self.label_encoders[col].classes_)\n",
        "                    print(f\"{col}: {self.feature_dims[col]} unique values\")\n",
        "                else:\n",
        "                    le = self.label_encoders[col]\n",
        "                    df[col] = df[col].astype(str).apply(\n",
        "                        lambda x: le.transform([x])[0] if x in le.classes_ else -1\n",
        "                    )\n",
        "        \n",
        "        print()\n",
        "        return df\n",
        "    \n",
        "    def normalize_features(self, df, fit=True):\n",
        "        \"\"\"Normalize numerical features\"\"\"\n",
        "        print(\"=== Normalizing Numerical Features ===\")\n",
        "        \n",
        "        numerical_cols = [col for col in NUMERICAL_FEATURES if col in df.columns]\n",
        "        \n",
        "        if fit:\n",
        "            df[numerical_cols] = self.scaler.fit_transform(df[numerical_cols])\n",
        "            print(f\"Normalized {len(numerical_cols)} numerical features\")\n",
        "        else:\n",
        "            df[numerical_cols] = self.scaler.transform(df[numerical_cols])\n",
        "            print(f\"Applied normalization to {len(numerical_cols)} features\")\n",
        "        \n",
        "        print()\n",
        "        return df\n",
        "    \n",
        "    def split_data(self, df):\n",
        "        \"\"\"Split data into train, validation, and test sets\"\"\"\n",
        "        print(\"=== Splitting Data ===\")\n",
        "        \n",
        "        # First split: train + val vs test\n",
        "        train_val, test = train_test_split(\n",
        "            df,\n",
        "            test_size=TEST_RATIO,\n",
        "            random_state=RANDOM_SEED,\n",
        "            stratify=df[CLASSIFICATION_TARGET]\n",
        "        )\n",
        "        \n",
        "        # Second split: train vs val\n",
        "        val_ratio_adjusted = VAL_RATIO / (TRAIN_RATIO + VAL_RATIO)\n",
        "        train, val = train_test_split(\n",
        "            train_val,\n",
        "            test_size=val_ratio_adjusted,\n",
        "            random_state=RANDOM_SEED,\n",
        "            stratify=train_val[CLASSIFICATION_TARGET]\n",
        "        )\n",
        "        \n",
        "        print(f\"Train set: {len(train)} samples ({len(train)/len(df)*100:.1f}%)\")\n",
        "        print(f\"Validation set: {len(val)} samples ({len(val)/len(df)*100:.1f}%)\")\n",
        "        print(f\"Test set: {len(test)} samples ({len(test)/len(df)*100:.1f}%)\")\n",
        "        print()\n",
        "        \n",
        "        return train, val, test\n",
        "    \n",
        "    def prepare_model_inputs(self, df):\n",
        "        \"\"\"Prepare X and y for model training\"\"\"\n",
        "        X_numerical = df[NUMERICAL_FEATURES].values\n",
        "        \n",
        "        X_categorical = {}\n",
        "        for col in CATEGORICAL_FEATURES:\n",
        "            if col in df.columns:\n",
        "                X_categorical[col] = df[col].values\n",
        "        \n",
        "        y_classification = df[CLASSIFICATION_TARGET].values\n",
        "        y_regression = df[REGRESSION_TARGET].values\n",
        "        \n",
        "        return X_numerical, X_categorical, y_classification, y_regression\n",
        "\n",
        "print(\"✓ DataPreprocessor class defined\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 1: Data Preprocessing\n",
        "print_banner(\"STEP 1: DATA PREPROCESSING\")\n",
        "\n",
        "# Initialize preprocessor\n",
        "preprocessor = DataPreprocessor()\n",
        "\n",
        "# Load and preprocess data\n",
        "df = preprocessor.load_data(DATASET_PATH)\n",
        "df = preprocessor.clean_data(df)\n",
        "df = preprocessor.engineer_features(df)\n",
        "df = preprocessor.encode_categorical(df, fit=True)\n",
        "df = preprocessor.normalize_features(df, fit=True)\n",
        "\n",
        "# Split data\n",
        "train_df, val_df, test_df = preprocessor.split_data(df)\n",
        "\n",
        "# Prepare model inputs\n",
        "X_train_num, X_train_cat, y_train_class, y_train_reg = preprocessor.prepare_model_inputs(train_df)\n",
        "X_val_num, X_val_cat, y_val_class, y_val_reg = preprocessor.prepare_model_inputs(val_df)\n",
        "X_test_num, X_test_cat, y_test_class, y_test_reg = preprocessor.prepare_model_inputs(test_df)\n",
        "\n",
        "print(f\"\\nData split completed:\")\n",
        "print(f\"  Training: {len(train_df)} samples\")\n",
        "print(f\"  Validation: {len(val_df)} samples\")\n",
        "print(f\"  Testing: {len(test_df)} samples\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# SE-CNN Model Architecture\n",
        "def se_block(input_tensor, reduction_ratio=16, name_prefix=''):\n",
        "    \"\"\"\n",
        "    Squeeze-and-Excitation (SE) block for channel attention\n",
        "    \"\"\"\n",
        "    channels = input_tensor.shape[-1]\n",
        "    \n",
        "    # Squeeze: Global Average Pooling\n",
        "    se = layers.GlobalAveragePooling1D(name=f'{name_prefix}_se_global_pool')(input_tensor)\n",
        "    \n",
        "    # Excitation: Two FC layers with ReLU and Sigmoid\n",
        "    se = layers.Dense(\n",
        "        channels // reduction_ratio,\n",
        "        activation='relu',\n",
        "        name=f'{name_prefix}_se_dense1'\n",
        "    )(se)\n",
        "    se = layers.Dense(\n",
        "        channels,\n",
        "        activation='sigmoid',\n",
        "        name=f'{name_prefix}_se_dense2'\n",
        "    )(se)\n",
        "    \n",
        "    # Reshape to (batch, 1, channels) for broadcasting\n",
        "    se = layers.Reshape((1, channels), name=f'{name_prefix}_se_reshape')(se)\n",
        "    \n",
        "    # Scale: Multiply input with attention weights\n",
        "    output = layers.Multiply(name=f'{name_prefix}_se_scale')([input_tensor, se])\n",
        "    \n",
        "    return output\n",
        "\n",
        "\n",
        "class MarketingSECNNModel:\n",
        "    def __init__(self, feature_dims):\n",
        "        self.feature_dims = feature_dims\n",
        "        self.model = None\n",
        "        \n",
        "    def build_model(self):\n",
        "        \"\"\"Build the SE-CNN architecture with multi-task heads\"\"\"\n",
        "        \n",
        "        # Input layers\n",
        "        numerical_input = layers.Input(\n",
        "            shape=(len(NUMERICAL_FEATURES),),\n",
        "            name='numerical_input'\n",
        "        )\n",
        "        \n",
        "        categorical_inputs = {}\n",
        "        categorical_embeddings = []\n",
        "        \n",
        "        for col in CATEGORICAL_FEATURES:\n",
        "            if col in self.feature_dims:\n",
        "                cat_input = layers.Input(shape=(1,), name=f'{col}_input', dtype='int32')\n",
        "                categorical_inputs[col] = cat_input\n",
        "                \n",
        "                embedding = layers.Embedding(\n",
        "                    input_dim=self.feature_dims[col] + 1,\n",
        "                    output_dim=EMBEDDING_DIM,\n",
        "                    name=f'{col}_embedding'\n",
        "                )(cat_input)\n",
        "                embedding = layers.Flatten()(embedding)\n",
        "                categorical_embeddings.append(embedding)\n",
        "        \n",
        "        # Concatenate all features\n",
        "        if categorical_embeddings:\n",
        "            concatenated = layers.Concatenate()(\n",
        "                [numerical_input] + categorical_embeddings\n",
        "            )\n",
        "        else:\n",
        "            concatenated = numerical_input\n",
        "        \n",
        "        # Reshape for 1D CNN\n",
        "        reshaped = layers.Reshape((-1, 1))(concatenated)\n",
        "        \n",
        "        # CNN Layers with SE blocks\n",
        "        conv1 = layers.Conv1D(\n",
        "            filters=CONV_FILTERS_1,\n",
        "            kernel_size=KERNEL_SIZE,\n",
        "            activation='relu',\n",
        "            padding='same',\n",
        "            name='conv1d_1'\n",
        "        )(reshaped)\n",
        "        conv1 = layers.BatchNormalization(name='bn1')(conv1)\n",
        "        conv1 = se_block(conv1, reduction_ratio=SE_REDUCTION_RATIO, name_prefix='se1')\n",
        "        conv1 = layers.MaxPooling1D(pool_size=POOL_SIZE, padding='same', name='pool1')(conv1)\n",
        "        conv1 = layers.Dropout(DROPOUT_RATE, name='dropout1')(conv1)\n",
        "        \n",
        "        conv2 = layers.Conv1D(\n",
        "            filters=CONV_FILTERS_2,\n",
        "            kernel_size=KERNEL_SIZE,\n",
        "            activation='relu',\n",
        "            padding='same',\n",
        "            name='conv1d_2'\n",
        "        )(conv1)\n",
        "        conv2 = layers.BatchNormalization(name='bn2')(conv2)\n",
        "        conv2 = se_block(conv2, reduction_ratio=SE_REDUCTION_RATIO, name_prefix='se2')\n",
        "        conv2 = layers.GlobalMaxPooling1D(name='global_pool')(conv2)\n",
        "        \n",
        "        # Dense layer\n",
        "        dense = layers.Dense(\n",
        "            DENSE_UNITS,\n",
        "            activation='relu',\n",
        "            name='dense_shared'\n",
        "        )(conv2)\n",
        "        dense = layers.Dropout(DROPOUT_RATE, name='dropout_shared')(dense)\n",
        "        \n",
        "        # Multi-task heads\n",
        "        classification_head = layers.Dense(\n",
        "            32,\n",
        "            activation='relu',\n",
        "            name='classification_dense'\n",
        "        )(dense)\n",
        "        classification_output = layers.Dense(\n",
        "            1,\n",
        "            activation='sigmoid',\n",
        "            name='classification_output'\n",
        "        )(classification_head)\n",
        "        \n",
        "        regression_head = layers.Dense(\n",
        "            32,\n",
        "            activation='relu',\n",
        "            name='regression_dense'\n",
        "        )(dense)\n",
        "        regression_output = layers.Dense(\n",
        "            1,\n",
        "            activation='linear',\n",
        "            name='regression_output'\n",
        "        )(regression_head)\n",
        "        \n",
        "        # Create model\n",
        "        inputs = [numerical_input] + list(categorical_inputs.values())\n",
        "        outputs = [classification_output, regression_output]\n",
        "        \n",
        "        self.model = Model(inputs=inputs, outputs=outputs, name='Marketing_SE_CNN')\n",
        "        return self.model\n",
        "    \n",
        "    def compile_model(self):\n",
        "        \"\"\"Compile model\"\"\"\n",
        "        losses = {\n",
        "            'classification_output': 'binary_crossentropy',\n",
        "            'regression_output': 'mse'\n",
        "        }\n",
        "        \n",
        "        loss_weights = {\n",
        "            'classification_output': CLASSIFICATION_LOSS_WEIGHT,\n",
        "            'regression_output': REGRESSION_LOSS_WEIGHT\n",
        "        }\n",
        "        \n",
        "        metrics = {\n",
        "            'classification_output': [\n",
        "                'accuracy',\n",
        "                keras.metrics.Precision(name='precision'),\n",
        "                keras.metrics.Recall(name='recall'),\n",
        "                keras.metrics.AUC(name='auc')\n",
        "            ],\n",
        "            'regression_output': [\n",
        "                'mae',\n",
        "                keras.metrics.RootMeanSquaredError(name='rmse')\n",
        "            ]\n",
        "        }\n",
        "        \n",
        "        optimizer = keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
        "        \n",
        "        self.model.compile(\n",
        "            optimizer=optimizer,\n",
        "            loss=losses,\n",
        "            loss_weights=loss_weights,\n",
        "            metrics=metrics\n",
        "        )\n",
        "        \n",
        "        print(\"\\n=== Model Compiled ===\")\n",
        "        print(f\"Classification loss weight: {CLASSIFICATION_LOSS_WEIGHT}\")\n",
        "        print(f\"Regression loss weight: {REGRESSION_LOSS_WEIGHT}\")\n",
        "        print(f\"Learning rate: {LEARNING_RATE}\")\n",
        "        print(f\"SE Reduction Ratio: {SE_REDUCTION_RATIO}\\n\")\n",
        "        \n",
        "        return self.model\n",
        "\n",
        "print(\"✓ SE-CNN Model architecture defined\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 2: Build Model\n",
        "print_banner(\"STEP 2: SE-CNN MODEL ARCHITECTURE\")\n",
        "print(\"Building model with Squeeze-and-Excitation blocks...\")\n",
        "\n",
        "model_builder = MarketingSECNNModel(preprocessor.feature_dims)\n",
        "model = model_builder.build_model()\n",
        "model = model_builder.compile_model()\n",
        "\n",
        "print(\"\\n=== Model Architecture ===\")\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 3: Train Model\n",
        "print_banner(\"STEP 3: MODEL TRAINING\")\n",
        "\n",
        "# Prepare inputs\n",
        "def prepare_inputs(X_num, X_cat):\n",
        "    inputs = [X_num]\n",
        "    for col in CATEGORICAL_FEATURES:\n",
        "        if col in X_cat:\n",
        "            inputs.append(X_cat[col])\n",
        "    return inputs\n",
        "\n",
        "train_inputs = prepare_inputs(X_train_num, X_train_cat)\n",
        "val_inputs = prepare_inputs(X_val_num, X_val_cat)\n",
        "\n",
        "train_outputs = {\n",
        "    'classification_output': y_train_class,\n",
        "    'regression_output': y_train_reg\n",
        "}\n",
        "val_outputs = {\n",
        "    'classification_output': y_val_class,\n",
        "    'regression_output': y_val_reg\n",
        "}\n",
        "\n",
        "# Setup callbacks\n",
        "callbacks = [\n",
        "    keras.callbacks.EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=EARLY_STOPPING_PATIENCE,\n",
        "        restore_best_weights=True,\n",
        "        verbose=1\n",
        "    ),\n",
        "    keras.callbacks.ReduceLROnPlateau(\n",
        "        monitor='val_loss',\n",
        "        patience=LR_REDUCTION_PATIENCE,\n",
        "        factor=LR_REDUCTION_FACTOR,\n",
        "        min_lr=MIN_LEARNING_RATE,\n",
        "        verbose=1\n",
        "    ),\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath=os.path.join(MODELS_DIR, 'se_cnn_marketing_model.h5'),\n",
        "        monitor='val_loss',\n",
        "        save_best_only=True,\n",
        "        verbose=1\n",
        "    )\n",
        "]\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STARTING MODEL TRAINING\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Training samples: {len(y_train_class)}\")\n",
        "print(f\"Validation samples: {len(y_val_class)}\")\n",
        "print(f\"Batch size: {BATCH_SIZE}\")\n",
        "print(f\"Max epochs: {EPOCHS}\")\n",
        "print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "# Train model\n",
        "history = model.fit(\n",
        "    train_inputs,\n",
        "    train_outputs,\n",
        "    validation_data=(val_inputs, val_outputs),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=callbacks,\n",
        "    verbose=TRAIN_VERBOSE\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"TRAINING COMPLETED\")\n",
        "print(\"=\"*60 + \"\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot Training History\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
        "fig.suptitle('Training History - SE-CNN Model', fontsize=16, fontweight='bold')\n",
        "\n",
        "history_dict = history.history\n",
        "\n",
        "# Total Loss\n",
        "axes[0, 0].plot(history_dict['loss'], label='Train Loss', linewidth=2)\n",
        "axes[0, 0].plot(history_dict['val_loss'], label='Val Loss', linewidth=2)\n",
        "axes[0, 0].set_title('Total Loss')\n",
        "axes[0, 0].set_xlabel('Epoch')\n",
        "axes[0, 0].set_ylabel('Loss')\n",
        "axes[0, 0].legend()\n",
        "axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# Classification Loss\n",
        "axes[0, 1].plot(history_dict['classification_output_loss'], label='Train', linewidth=2)\n",
        "axes[0, 1].plot(history_dict['val_classification_output_loss'], label='Val', linewidth=2)\n",
        "axes[0, 1].set_title('Classification Loss')\n",
        "axes[0, 1].set_xlabel('Epoch')\n",
        "axes[0, 1].set_ylabel('Loss')\n",
        "axes[0, 1].legend()\n",
        "axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "# Regression Loss\n",
        "axes[0, 2].plot(history_dict['regression_output_loss'], label='Train', linewidth=2)\n",
        "axes[0, 2].plot(history_dict['val_regression_output_loss'], label='Val', linewidth=2)\n",
        "axes[0, 2].set_title('Regression Loss (MSE)')\n",
        "axes[0, 2].set_xlabel('Epoch')\n",
        "axes[0, 2].set_ylabel('Loss')\n",
        "axes[0, 2].legend()\n",
        "axes[0, 2].grid(True, alpha=0.3)\n",
        "\n",
        "# Classification Accuracy\n",
        "axes[1, 0].plot(history_dict['classification_output_accuracy'], label='Train', linewidth=2)\n",
        "axes[1, 0].plot(history_dict['val_classification_output_accuracy'], label='Val', linewidth=2)\n",
        "axes[1, 0].set_title('Classification Accuracy')\n",
        "axes[1, 0].set_xlabel('Epoch')\n",
        "axes[1, 0].set_ylabel('Accuracy')\n",
        "axes[1, 0].legend()\n",
        "axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# Classification AUC\n",
        "axes[1, 1].plot(history_dict['classification_output_auc'], label='Train', linewidth=2)\n",
        "axes[1, 1].plot(history_dict['val_classification_output_auc'], label='Val', linewidth=2)\n",
        "axes[1, 1].set_title('Classification AUC')\n",
        "axes[1, 1].set_xlabel('Epoch')\n",
        "axes[1, 1].set_ylabel('AUC')\n",
        "axes[1, 1].legend()\n",
        "axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "# Regression MAE\n",
        "axes[1, 2].plot(history_dict['regression_output_mae'], label='Train', linewidth=2)\n",
        "axes[1, 2].plot(history_dict['val_regression_output_mae'], label='Val', linewidth=2)\n",
        "axes[1, 2].set_title('Regression MAE')\n",
        "axes[1, 2].set_xlabel('Epoch')\n",
        "axes[1, 2].set_ylabel('MAE')\n",
        "axes[1, 2].legend()\n",
        "axes[1, 2].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(RESULTS_DIR, 'training_history.png'), dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(f\"Training plots saved to {os.path.join(RESULTS_DIR, 'training_history.png')}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 4: Model Evaluation\n",
        "print_banner(\"STEP 4: MODEL EVALUATION\")\n",
        "\n",
        "test_inputs = prepare_inputs(X_test_num, X_test_cat)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"EVALUATING SE-CNN MODEL ON TEST SET\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Test samples: {len(y_test_class)}\")\n",
        "print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "# Make predictions\n",
        "print(\"Making predictions...\")\n",
        "predictions = model.predict(test_inputs, verbose=0)\n",
        "\n",
        "predictions_dict = {\n",
        "    'classification_probs': predictions[0].flatten(),\n",
        "    'classification_labels': (predictions[0] > 0.5).astype(int).flatten(),\n",
        "    'regression_values': predictions[1].flatten()\n",
        "}\n",
        "\n",
        "# Evaluate classification\n",
        "print(\"Evaluating classification...\")\n",
        "y_pred_class = predictions_dict['classification_labels']\n",
        "y_probs = predictions_dict['classification_probs']\n",
        "\n",
        "classification_metrics = {\n",
        "    'accuracy': accuracy_score(y_test_class, y_pred_class),\n",
        "    'precision': precision_score(y_test_class, y_pred_class, zero_division=0),\n",
        "    'recall': recall_score(y_test_class, y_pred_class, zero_division=0),\n",
        "    'f1_score': f1_score(y_test_class, y_pred_class, zero_division=0),\n",
        "    'auc': roc_auc_score(y_test_class, y_probs)\n",
        "}\n",
        "\n",
        "# Evaluate regression\n",
        "print(\"Evaluating regression...\")\n",
        "y_pred_reg = predictions_dict['regression_values']\n",
        "\n",
        "regression_metrics = {\n",
        "    'mae': mean_absolute_error(y_test_reg, y_pred_reg),\n",
        "    'rmse': np.sqrt(mean_squared_error(y_test_reg, y_pred_reg)),\n",
        "    'r2': r2_score(y_test_reg, y_pred_reg)\n",
        "}\n",
        "\n",
        "# Print evaluation report\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"MODEL EVALUATION REPORT (SE-CNN)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"\\n--- Classification Metrics ---\")\n",
        "for metric, value in classification_metrics.items():\n",
        "    print(f\"{metric.upper()}: {value:.4f}\")\n",
        "\n",
        "print(\"\\n--- Regression Metrics ---\")\n",
        "for metric, value in regression_metrics.items():\n",
        "    print(f\"{metric.upper()}: {value:.4f}\")\n",
        "\n",
        "print(\"=\"*60 + \"\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot Confusion Matrix\n",
        "cm = confusion_matrix(y_test_class, y_pred_class)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=True,\n",
        "            xticklabels=['Low Performing', 'High Performing'],\n",
        "            yticklabels=['Low Performing', 'High Performing'])\n",
        "plt.title('Confusion Matrix - SE-CNN Model', fontsize=14, fontweight='bold')\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(RESULTS_DIR, 'confusion_matrix.png'), dpi=300, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot ROC Curve\n",
        "fpr, tpr, _ = roc_curve(y_test_class, y_probs)\n",
        "auc = classification_metrics['auc']\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, linewidth=2, label=f'ROC Curve (AUC = {auc:.4f})')\n",
        "plt.plot([0, 1], [0, 1], 'k--', linewidth=1, label='Random Classifier')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve - SE-CNN Model', fontsize=14, fontweight='bold')\n",
        "plt.legend(loc='lower right')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(RESULTS_DIR, 'roc_curve.png'), dpi=300, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot Regression Results\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Scatter plot\n",
        "axes[0].scatter(y_test_reg, y_pred_reg, alpha=0.5, s=30)\n",
        "axes[0].plot([y_test_reg.min(), y_test_reg.max()],\n",
        "             [y_test_reg.min(), y_test_reg.max()],\n",
        "             'r--', linewidth=2, label='Perfect Prediction')\n",
        "axes[0].set_xlabel('True LTV')\n",
        "axes[0].set_ylabel('Predicted LTV')\n",
        "axes[0].set_title('LTV: Predicted vs Actual')\n",
        "axes[0].legend()\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# Residual plot\n",
        "residuals = y_test_reg - y_pred_reg\n",
        "axes[1].scatter(y_pred_reg, residuals, alpha=0.5, s=30)\n",
        "axes[1].axhline(y=0, color='r', linestyle='--', linewidth=2)\n",
        "axes[1].set_xlabel('Predicted LTV')\n",
        "axes[1].set_ylabel('Residuals')\n",
        "axes[1].set_title('Residual Plot')\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.suptitle(f'Regression Results - SE-CNN (MAE: {regression_metrics[\"mae\"]:.4f}, R²: {regression_metrics[\"r2\"]:.4f})',\n",
        "             fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(RESULTS_DIR, 'regression_results.png'), dpi=300, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare with Baseline Models\n",
        "baseline_results = [\n",
        "    {'Model': 'Logistic Regression', 'Precision (%)': 71.2, 'Recall (%)': 68.9, 'Accuracy (%)': 73.5, 'AUC': 0.781},\n",
        "    {'Model': 'XGBoost', 'Precision (%)': 75.9, 'Recall (%)': 73.8, 'Accuracy (%)': 77.4, 'AUC': 0.826},\n",
        "    {'Model': 'WDL', 'Precision (%)': 79.8, 'Recall (%)': 78.4, 'Accuracy (%)': 81.6, 'AUC': 0.857},\n",
        "]\n",
        "\n",
        "comparison_df = pd.DataFrame(baseline_results)\n",
        "\n",
        "# Add SE-CNN results\n",
        "se_cnn_results = {\n",
        "    'Model': 'SE-CNN (Proposed)',\n",
        "    'Precision (%)': classification_metrics['precision'] * 100,\n",
        "    'Recall (%)': classification_metrics['recall'] * 100,\n",
        "    'Accuracy (%)': classification_metrics['accuracy'] * 100,\n",
        "    'AUC': classification_metrics['auc']\n",
        "}\n",
        "comparison_df = pd.concat([comparison_df, pd.DataFrame([se_cnn_results])], ignore_index=True)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"COMPARISON WITH BASELINE MODELS\")\n",
        "print(\"=\"*60)\n",
        "print(\"\\n\", comparison_df.to_string(index=False))\n",
        "print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "# Plot comparison\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Accuracy and Precision\n",
        "x = np.arange(len(comparison_df))\n",
        "width = 0.35\n",
        "\n",
        "axes[0].bar(x - width/2, comparison_df['Accuracy (%)'], width, label='Accuracy', alpha=0.8)\n",
        "axes[0].bar(x + width/2, comparison_df['Precision (%)'], width, label='Precision', alpha=0.8)\n",
        "axes[0].set_xlabel('Models')\n",
        "axes[0].set_ylabel('Score (%)')\n",
        "axes[0].set_title('Accuracy & Precision Comparison')\n",
        "axes[0].set_xticks(x)\n",
        "axes[0].set_xticklabels(comparison_df['Model'], rotation=15, ha='right')\n",
        "axes[0].legend()\n",
        "axes[0].grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "# AUC\n",
        "axes[1].bar(comparison_df['Model'], comparison_df['AUC'], alpha=0.8, color='green')\n",
        "axes[1].set_xlabel('Models')\n",
        "axes[1].set_ylabel('AUC')\n",
        "axes[1].set_title('AUC Comparison')\n",
        "axes[1].set_xticklabels(comparison_df['Model'], rotation=15, ha='right')\n",
        "axes[1].grid(True, alpha=0.3, axis='y')\n",
        "axes[1].set_ylim([0.7, 1.0])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(RESULTS_DIR, 'baseline_comparison.png'), dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# Save comparison\n",
        "comparison_df.to_csv(os.path.join(RESULTS_DIR, 'model_comparison.csv'), index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 5: Budget Optimization\n",
        "print_banner(\"STEP 5: BUDGET OPTIMIZATION\")\n",
        "\n",
        "# Decode categorical features for optimization\n",
        "test_df_opt = test_df.copy()\n",
        "for col, encoder in preprocessor.label_encoders.items():\n",
        "    if col in test_df_opt.columns:\n",
        "        encoded_values = test_df_opt[col].values\n",
        "        decoded_values = []\n",
        "        for val in encoded_values:\n",
        "            try:\n",
        "                if val >= 0 and val < len(encoder.classes_):\n",
        "                    decoded_values.append(encoder.classes_[val])\n",
        "                else:\n",
        "                    decoded_values.append('Unknown')\n",
        "            except:\n",
        "                decoded_values.append('Unknown')\n",
        "        test_df_opt[col] = decoded_values\n",
        "\n",
        "print(\"✓ Decoded categorical features to actual names\")\n",
        "\n",
        "# Add predictions to dataframe\n",
        "test_df_opt['Predicted_Prob'] = predictions_dict['classification_probs']\n",
        "test_df_opt['Predicted_LTV'] = predictions_dict['regression_values']\n",
        "\n",
        "# Calculate expected value\n",
        "test_df_opt['Expected_Value'] = (\n",
        "    test_df_opt['Predicted_Prob'] *\n",
        "    test_df_opt['ROI'] *\n",
        "    test_df_opt['Predicted_LTV']\n",
        ")\n",
        "\n",
        "# Filter campaigns with positive expected value\n",
        "test_df_opt = test_df_opt[test_df_opt['Expected_Value'] > 0].reset_index(drop=True)\n",
        "\n",
        "print(f\"\\nCampaigns eligible for optimization: {len(test_df_opt)}\")\n",
        "\n",
        "# Budget Optimization using Linear Programming with two strategies\n",
        "n_campaigns = len(test_df_opt)\n",
        "allocation_strategy = None\n",
        "optimal_budgets = None\n",
        "\n",
        "# Strategy 1: Try full optimization with platform constraints\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"SOLVING BUDGET OPTIMIZATION PROBLEM\")\n",
        "print(\"=\"*60)\n",
        "print(\"\\nAttempt 1: Full optimization with platform constraints...\")\n",
        "\n",
        "try:\n",
        "    prob_full = LpProblem(\"Marketing_Budget_Optimization\", LpMaximize)\n",
        "    \n",
        "    # Decision variables with minimum budget\n",
        "    budgets_full = {\n",
        "        i: LpVariable(f\"budget_{i}\",\n",
        "                     lowBound=MIN_BUDGET_PER_CAMPAIGN,\n",
        "                     upBound=MAX_BUDGET_PER_CAMPAIGN)\n",
        "        for i in range(n_campaigns)\n",
        "    }\n",
        "    \n",
        "    # Objective: Maximize total expected value\n",
        "    prob_full += lpSum([\n",
        "        budgets_full[i] * test_df_opt.loc[i, 'Expected_Value']\n",
        "        for i in range(n_campaigns)\n",
        "    ]), \"Total_Expected_Value\"\n",
        "    \n",
        "    # Constraint 1: Total budget\n",
        "    prob_full += lpSum([budgets_full[i] for i in range(n_campaigns)]) <= TOTAL_BUDGET, \"Total_Budget_Constraint\"\n",
        "    \n",
        "    # Constraint 2: Platform-wise budget constraints\n",
        "    platforms = test_df_opt['Platform'].unique()\n",
        "    platform_counts = test_df_opt['Platform'].value_counts()\n",
        "    print(f\"\\nPlatform distribution: {platform_counts.to_dict()}\")\n",
        "    \n",
        "    for platform in platforms:\n",
        "        platform_indices = test_df_opt[test_df_opt['Platform'] == platform].index.tolist()\n",
        "        \n",
        "        if platform in PLATFORM_BUDGET_CONSTRAINTS and len(platform_indices) > 0:\n",
        "            min_pct, max_pct = PLATFORM_BUDGET_CONSTRAINTS[platform]\n",
        "            \n",
        "            # Check if constraints are feasible\n",
        "            min_required = min_pct * TOTAL_BUDGET\n",
        "            max_allowed = max_pct * TOTAL_BUDGET\n",
        "            min_possible = len(platform_indices) * MIN_BUDGET_PER_CAMPAIGN\n",
        "            max_possible = len(platform_indices) * MAX_BUDGET_PER_CAMPAIGN\n",
        "            \n",
        "            # Only add constraint if feasible\n",
        "            if min_required <= max_possible and max_allowed >= min_possible:\n",
        "                prob_full += (\n",
        "                    lpSum([budgets_full[i] for i in platform_indices]) >= min_required\n",
        "                ), f\"{platform}_Min_Budget\"\n",
        "                \n",
        "                prob_full += (\n",
        "                    lpSum([budgets_full[i] for i in platform_indices]) <= max_allowed\n",
        "                ), f\"{platform}_Max_Budget\"\n",
        "            else:\n",
        "                print(f\"Skipping infeasible constraints for {platform}\")\n",
        "    \n",
        "    # Solve\n",
        "    prob_full.solve()\n",
        "    \n",
        "    if LpStatus[prob_full.status] == 'Optimal':\n",
        "        print(\"✓ Full optimization successful!\")\n",
        "        optimal_budgets = [pulp.value(budgets_full[i]) for i in range(n_campaigns)]\n",
        "        allocation_strategy = 'constraint'\n",
        "    else:\n",
        "        print(f\"Full optimization status: {LpStatus[prob_full.status]}\")\n",
        "        raise Exception(\"Full optimization not optimal\")\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"Full optimization failed: {str(e)}\")\n",
        "    \n",
        "    # Strategy 2: Try relaxed optimization (no platform constraints)\n",
        "    print(\"\\nAttempting optimization with relaxed constraints...\")\n",
        "    try:\n",
        "        prob_relaxed = LpProblem(\"Marketing_Budget_Optimization_Relaxed\", LpMaximize)\n",
        "        \n",
        "        # Decision variables with relaxed bounds (allow zero)\n",
        "        budgets_relaxed = {\n",
        "            i: LpVariable(f\"budget_{i}\",\n",
        "                         lowBound=0,\n",
        "                         upBound=MAX_BUDGET_PER_CAMPAIGN)\n",
        "            for i in range(n_campaigns)\n",
        "        }\n",
        "        \n",
        "        # Objective: Maximize total expected value\n",
        "        prob_relaxed += lpSum([\n",
        "            budgets_relaxed[i] * test_df_opt.loc[i, 'Expected_Value']\n",
        "            for i in range(n_campaigns)\n",
        "        ]), \"Total_Expected_Value\"\n",
        "        \n",
        "        # Only constraint: Total budget limit\n",
        "        prob_relaxed += lpSum([budgets_relaxed[i] for i in range(n_campaigns)]) <= TOTAL_BUDGET, \"Total_Budget_Constraint\"\n",
        "        \n",
        "        # Solve\n",
        "        prob_relaxed.solve()\n",
        "        \n",
        "        if LpStatus[prob_relaxed.status] == 'Optimal':\n",
        "            print(\"✓ Relaxed optimization successful!\")\n",
        "            optimal_budgets = [pulp.value(budgets_relaxed[i]) for i in range(n_campaigns)]\n",
        "            allocation_strategy = 'flexible'\n",
        "        else:\n",
        "            print(f\"Relaxed optimization status: {LpStatus[prob_relaxed.status]}\")\n",
        "            optimal_budgets = None\n",
        "    except Exception as e2:\n",
        "        print(f\"Relaxed optimization failed: {str(e2)}\")\n",
        "        optimal_budgets = None\n",
        "\n",
        "# Apply results\n",
        "if optimal_budgets is not None:\n",
        "    test_df_opt['Optimal_Budget'] = optimal_budgets\n",
        "    \n",
        "    # Filter out zero-budget campaigns\n",
        "    test_df_opt = test_df_opt[test_df_opt['Optimal_Budget'] > 0].reset_index(drop=True)\n",
        "    \n",
        "    # Calculate metrics\n",
        "    total_allocated = test_df_opt['Optimal_Budget'].sum()\n",
        "    total_expected_roi = (test_df_opt['Optimal_Budget'] * test_df_opt['Expected_Value']).sum()\n",
        "    budget_utilization = (total_allocated / TOTAL_BUDGET) * 100\n",
        "    \n",
        "    print(f\"\\nTotal Budget Allocated: ${total_allocated:,.2f}\")\n",
        "    print(f\"Budget Utilization: {budget_utilization:.2f}%\")\n",
        "    print(f\"Expected Total ROI: {total_expected_roi:,.2f}\")\n",
        "    print(f\"Campaigns Funded: {len(test_df_opt)}\")\n",
        "    print(f\"Allocation Strategy: {allocation_strategy}\")\n",
        "    print(\"=\"*60 + \"\\n\")\n",
        "else:\n",
        "    print(\"\\nNo feasible budget allocation found using constraint or flexible strategies.\")\n",
        "    test_df_opt['Optimal_Budget'] = 0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Budget Allocation Analysis\n",
        "if optimal_budgets is not None and len(test_df_opt[test_df_opt['Optimal_Budget'] > 0]) > 0:\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"BUDGET ALLOCATION ANALYSIS\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    # Platform-wise allocation\n",
        "    print(\"\\n--- Platform-wise Budget Allocation ---\")\n",
        "    platform_allocation = test_df_opt.groupby('Platform')['Optimal_Budget'].agg(['sum', 'count', 'mean'])\n",
        "    platform_allocation['percentage'] = (platform_allocation['sum'] / total_allocated) * 100\n",
        "    platform_allocation.columns = ['Total Budget ($)', 'Campaigns', 'Avg Budget ($)', 'Percentage (%)']\n",
        "    print(platform_allocation.to_string())\n",
        "    \n",
        "    # Country-wise allocation (Top 10)\n",
        "    print(\"\\n--- Country-wise Budget Allocation (Top 10) ---\")\n",
        "    country_allocation = test_df_opt.groupby('Country')['Optimal_Budget'].agg(['sum', 'count', 'mean'])\n",
        "    country_allocation['percentage'] = (country_allocation['sum'] / total_allocated) * 100\n",
        "    country_allocation.columns = ['Total Budget ($)', 'Campaigns', 'Avg Budget ($)', 'Percentage (%)']\n",
        "    country_allocation = country_allocation.sort_values('Total Budget ($)', ascending=False).head(10)\n",
        "    print(country_allocation.to_string())\n",
        "    \n",
        "    # Performance-based allocation\n",
        "    print(\"\\n--- High vs Low Performing Campaigns ---\")\n",
        "    perf_allocation = test_df_opt.groupby(CLASSIFICATION_TARGET)['Optimal_Budget'].agg(['sum', 'count', 'mean'])\n",
        "    perf_allocation['percentage'] = (perf_allocation['sum'] / total_allocated) * 100\n",
        "    perf_allocation.columns = ['Total Budget ($)', 'Campaigns', 'Avg Budget ($)', 'Percentage (%)']\n",
        "    perf_allocation.index = ['Low Performing', 'High Performing']\n",
        "    print(perf_allocation.to_string())\n",
        "    \n",
        "    print(\"=\"*60 + \"\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize Budget Allocation\n",
        "if optimal_budgets is not None and len(test_df_opt[test_df_opt['Optimal_Budget'] > 0]) > 0:\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "    \n",
        "    # Platform allocation (pie chart)\n",
        "    platform_data = test_df_opt.groupby('Platform')['Optimal_Budget'].sum().sort_values(ascending=False)\n",
        "    colors = sns.color_palette('Set3', len(platform_data))\n",
        "    axes[0, 0].pie(platform_data.values, labels=platform_data.index, autopct='%1.1f%%',\n",
        "                   startangle=90, colors=colors)\n",
        "    axes[0, 0].set_title('Platform-wise Budget Distribution', fontweight='bold', fontsize=14)\n",
        "    \n",
        "    # Country allocation (top 10 bar chart)\n",
        "    country_data = test_df_opt.groupby('Country')['Optimal_Budget'].sum().sort_values(ascending=False).head(10)\n",
        "    axes[0, 1].barh(range(len(country_data)), country_data.values, color='steelblue')\n",
        "    axes[0, 1].set_yticks(range(len(country_data)))\n",
        "    axes[0, 1].set_yticklabels(country_data.index, fontsize=10)\n",
        "    axes[0, 1].set_xlabel('Budget ($)', fontsize=11)\n",
        "    axes[0, 1].set_title('Top 10 Countries by Budget Allocation', fontweight='bold', fontsize=14)\n",
        "    axes[0, 1].invert_yaxis()\n",
        "    axes[0, 1].grid(axis='x', alpha=0.3)\n",
        "    \n",
        "    # Add value labels\n",
        "    for i, v in enumerate(country_data.values):\n",
        "        axes[0, 1].text(v, i, f' ${v:,.0f}', va='center', fontsize=9)\n",
        "    \n",
        "    # Budget vs Expected Value (scatter)\n",
        "    scatter = axes[1, 0].scatter(test_df_opt['Optimal_Budget'],\n",
        "                      test_df_opt['Expected_Value'],\n",
        "                      alpha=0.6, s=50, c=test_df_opt['Predicted_Prob'],\n",
        "                      cmap='viridis', edgecolors='black', linewidth=0.5)\n",
        "    axes[1, 0].set_xlabel('Optimal Budget ($)', fontsize=11)\n",
        "    axes[1, 0].set_ylabel('Expected Value', fontsize=11)\n",
        "    axes[1, 0].set_title('Budget Allocation vs Expected Value', fontweight='bold', fontsize=14)\n",
        "    axes[1, 0].grid(True, alpha=0.3)\n",
        "    cbar = plt.colorbar(scatter, ax=axes[1, 0])\n",
        "    cbar.set_label('Success Probability', fontsize=10)\n",
        "    \n",
        "    # Budget distribution (histogram)\n",
        "    axes[1, 1].hist(test_df_opt['Optimal_Budget'], bins=30, color='coral', edgecolor='black', alpha=0.7)\n",
        "    axes[1, 1].set_xlabel('Budget ($)', fontsize=11)\n",
        "    axes[1, 1].set_ylabel('Frequency', fontsize=11)\n",
        "    axes[1, 1].set_title('Budget Distribution Across Campaigns', fontweight='bold', fontsize=14)\n",
        "    mean_budget = test_df_opt['Optimal_Budget'].mean()\n",
        "    axes[1, 1].axvline(mean_budget, color='red',\n",
        "                      linestyle='--', linewidth=2, label=f\"Mean: ${mean_budget:,.0f}\")\n",
        "    axes[1, 1].legend(fontsize=10)\n",
        "    axes[1, 1].grid(True, alpha=0.3, axis='y')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(RESULTS_DIR, 'budget_allocation.png'), dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    \n",
        "    print(f\"Allocation plots saved to {os.path.join(RESULTS_DIR, 'budget_allocation.png')}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Export Budget Recommendations\n",
        "if optimal_budgets is not None and len(test_df_opt[test_df_opt['Optimal_Budget'] > 0]) > 0:\n",
        "    # Select relevant columns for export\n",
        "    export_cols = ['Ad_ID', 'Campaign_ID', 'Campaign_Name', 'Platform', 'Country',\n",
        "                   'CPC_USD', 'CTR', 'ROI', 'Predicted_Prob', 'Predicted_LTV',\n",
        "                   'Expected_Value', 'Optimal_Budget', CLASSIFICATION_TARGET]\n",
        "    \n",
        "    # Only include columns that exist\n",
        "    export_cols = [col for col in export_cols if col in test_df_opt.columns]\n",
        "    \n",
        "    export_df = test_df_opt[export_cols].sort_values('Optimal_Budget', ascending=False)\n",
        "    export_path = os.path.join(RESULTS_DIR, 'budget_recommendations.csv')\n",
        "    export_df.to_csv(export_path, index=False)\n",
        "    \n",
        "    print(f\"\\nBudget recommendations exported to {export_path}\")\n",
        "    print(f\"\\nTop 10 Budget Recommendations:\")\n",
        "    print(export_df.head(10).to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate Summary Report\n",
        "print_banner(\"SUMMARY REPORT\")\n",
        "\n",
        "report_path = os.path.join(RESULTS_DIR, 'summary_report.txt')\n",
        "\n",
        "with open(report_path, 'w') as f:\n",
        "    f.write(\"=\"*80 + \"\\n\")\n",
        "    f.write(\"SE-CNN-BASED MARKETING OPTIMIZATION - SUMMARY REPORT\\n\")\n",
        "    f.write(\"=\"*80 + \"\\n\\n\")\n",
        "    \n",
        "    f.write(f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
        "    f.write(f\"Model Type: SE-CNN (Squeeze-and-Excitation CNN)\\n\\n\")\n",
        "    \n",
        "    f.write(\"-\" * 80 + \"\\n\")\n",
        "    f.write(\"TRAINING RESULTS\\n\")\n",
        "    f.write(\"-\" * 80 + \"\\n\")\n",
        "    f.write(f\"Final Train Loss: {history_dict['loss'][-1]:.4f}\\n\")\n",
        "    f.write(f\"Final Val Loss: {history_dict['val_loss'][-1]:.4f}\\n\")\n",
        "    f.write(f\"Final Train Accuracy: {history_dict['classification_output_accuracy'][-1]:.4f}\\n\")\n",
        "    f.write(f\"Final Val Accuracy: {history_dict['val_classification_output_accuracy'][-1]:.4f}\\n\")\n",
        "    f.write(f\"Best Epoch: {np.argmin(history_dict['val_loss']) + 1}\\n\")\n",
        "    f.write(f\"Total Epochs: {len(history_dict['loss'])}\\n\\n\")\n",
        "    \n",
        "    f.write(\"-\" * 80 + \"\\n\")\n",
        "    f.write(\"EVALUATION RESULTS\\n\")\n",
        "    f.write(\"-\" * 80 + \"\\n\")\n",
        "    f.write(\"\\nClassification Metrics:\\n\")\n",
        "    for key, value in classification_metrics.items():\n",
        "        f.write(f\"  {key}: {value:.4f}\\n\")\n",
        "    \n",
        "    f.write(\"\\nRegression Metrics:\\n\")\n",
        "    for key, value in regression_metrics.items():\n",
        "        f.write(f\"  {key}: {value:.4f}\\n\")\n",
        "    f.write(\"\\n\")\n",
        "    \n",
        "    f.write(\"-\" * 80 + \"\\n\")\n",
        "    f.write(\"OPTIMIZATION RESULTS\\n\")\n",
        "    f.write(\"-\" * 80 + \"\\n\")\n",
        "    if optimal_budgets is not None and len(test_df_opt[test_df_opt['Optimal_Budget'] > 0]) > 0:\n",
        "        f.write(f\"Total Budget Allocated: ${total_allocated:,.2f}\\n\")\n",
        "        f.write(f\"Budget Utilization: {budget_utilization:.2f}%\\n\")\n",
        "        f.write(f\"Expected Total ROI: {total_expected_roi:,.2f}\\n\")\n",
        "        f.write(f\"Campaigns Funded: {len(test_df_opt[test_df_opt['Optimal_Budget'] > 0])}\\n\")\n",
        "    else:\n",
        "        f.write(\"Budget optimization was not successful.\\n\")\n",
        "    \n",
        "    f.write(\"\\n\" + \"=\"*80 + \"\\n\")\n",
        "    f.write(\"END OF REPORT\\n\")\n",
        "    f.write(\"=\"*80 + \"\\n\")\n",
        "\n",
        "# Print report\n",
        "with open(report_path, 'r') as f:\n",
        "    print(\"\\n\" + f.read())\n",
        "\n",
        "print(f\"\\nSummary report saved to {report_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Results Summary\n",
        "\n",
        "All results have been generated and saved:\n",
        "\n",
        "1. **Model**: Saved to `/content/models/se_cnn_marketing_model.h5`\n",
        "2. **Training History Plot**: `/content/results/training_history.png`\n",
        "3. **Confusion Matrix**: `/content/results/confusion_matrix.png`\n",
        "4. **ROC Curve**: `/content/results/roc_curve.png`\n",
        "5. **Regression Results**: `/content/results/regression_results.png`\n",
        "6. **Baseline Comparison**: `/content/results/baseline_comparison.png`\n",
        "7. **Budget Allocation**: `/content/results/budget_allocation.png`\n",
        "8. **Budget Recommendations**: `/content/results/budget_recommendations.csv`\n",
        "9. **Model Comparison**: `/content/results/model_comparison.csv`\n",
        "10. **Summary Report**: `/content/results/summary_report.txt`\n",
        "\n",
        "You can download these files using the file browser in Colab or by running:\n",
        "```python\n",
        "from google.colab import files\n",
        "files.download('/content/results/summary_report.txt')\n",
        "```\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
